Command:
python test_script.py -s smallest_subclass -d 5 -n 100 --seed 56 -m ripper --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.037500000000000006
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.039999999999999994
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 100 remain. 
Dimension is 5.

Computed total variation: 0.43999999999999995
Importing dev version v0.982 of RIPPER
RIPPER:
FULL MODEL:
  Accruacy: 0.6
  Our objective: 0.19999999999999996

IF 
    (x2 = 1)            <-- (term's our objective: -0.07999999999999996)
 OR (x3 = 1 AND x4 = 0) <-- (term's our objective: -0.019999999999999962)
 OR (x1 = 0 AND x3 = 1) <-- (term's our objective: 0.06000000000000005)
 OR (x0 = 1 AND x4 = 1) <-- (term's our objective: 0.19999999999999998)
 OR (x4 = 0 AND x0 = 0) <-- (term's our objective: 0.18)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 3.1192715167999268
Best over terms:
  Our final objective: 0.19999999999999998
    Its accruacy: 0.6
    Its hamming distance: 7
  Shortest hamming distance: 3
    Its our objective: 0.18
  Highest accruacy: 0.6

Errors:

