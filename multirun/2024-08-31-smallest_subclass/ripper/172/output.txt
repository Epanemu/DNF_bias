Command:
python test_script.py -s smallest_subclass -d 5 -n 100 --seed 73 -m ripper --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.037500000000000006
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.06
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 100 remain. 
Dimension is 5.

Computed total variation: 0.33999999999999997
Importing dev version v0.982 of RIPPER
RIPPER:
FULL MODEL:
  Accruacy: 0.52
  Our objective: 0.040000000000000036

IF 
    (x0 = 0)            <-- (term's our objective: 0.10000000000000003)
 OR (x1 = 1)            <-- (term's our objective: -0.16000000000000003)
 OR (x2 = 0 AND x3 = 1) <-- (term's our objective: 0.10000000000000003)
 OR (x3 = 0 AND x4 = 0) <-- (term's our objective: 0.08000000000000004)
 OR (x2 = 1 AND x4 = 1) <-- (term's our objective: -0.10000000000000003)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 3.150709629058838
Best over terms:
  Our final objective: 0.10000000000000003
    Its accruacy: 0.55
    Its hamming distance: 4
  Shortest hamming distance: 3
    Its our objective: 0.08000000000000004
  Highest accruacy: 0.55

Errors:

