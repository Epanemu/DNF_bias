Command:
python test_script.py -s smallest_subclass -d 5 -n 10000 --seed 34 -m dnf_mio --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.037500000000000006
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.0344
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 10000 remain. 
Dimension is 5.

Computed total variation: 0.06439999999999999
DNF using MIO
Set parameter TimeLimit to value 120
Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))

CPU model: Intel(R) Core(TM) i9-14900HX, instruction set [SSE2|AVX|AVX2]
Thread count: 24 physical cores, 32 logical processors, using up to 32 threads

Optimize a model with 280000 rows, 35050 columns and 555000 nonzeros
Model fingerprint: 0xe6eeecf7
Variable types: 35000 continuous, 50 integer (50 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [2e-04, 2e-04]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 4e+00]
Found heuristic solution: objective 1.0000000
Presolve removed 279008 rows and 34776 columns
Presolve time: 0.40s
Presolved: 992 rows, 274 columns, 2752 nonzeros
Variable types: 0 continuous, 274 integer (274 binary)

Root relaxation: objective 0.000000e+00, 207 iterations, 0.00 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   84    1.00000    0.00000   100%     -    0s
H    0     0                       0.9964000    0.00000   100%     -    0s
     0     0    0.00000    0   78    0.99640    0.00000   100%     -    0s
H    0     0                       0.9956000    0.00000   100%     -    0s
H    0     0                       0.9648000    0.04762  95.1%     -    0s
     0     0    0.12448    0  226    0.96480    0.12448  87.1%     -    0s
     0     0    0.18851    0  216    0.96480    0.18851  80.5%     -    0s
     0     0    0.93560    0   39    0.96480    0.93560  3.03%     -    0s
H    0     0                       0.9422000    0.93560  0.70%     -    0s
H    0     0                       0.9414000    0.93560  0.62%     -    0s
     0     0    0.93560    0   41    0.94140    0.93560  0.62%     -    0s
     0     0    0.93560    0   43    0.94140    0.93560  0.62%     -    0s
H    0     0                       0.9386000    0.93560  0.32%     -    0s
H    0     0                       0.9380000    0.93560  0.26%     -    0s
     0     0    0.93560    0   51    0.93800    0.93560  0.26%     -    0s
     0     0    0.93560    0   32    0.93800    0.93560  0.26%     -    0s
     0     0    0.93560    0   69    0.93800    0.93560  0.26%     -    0s
H    0     0                       0.9378000    0.93560  0.23%     -    0s
     0     0    0.93560    0   45    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   51    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   51    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   49    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   31    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   30    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   28    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   30    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   28    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   60    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   53    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   50    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   54    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   48    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   25    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   24    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   43    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   39    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   32    0.93780    0.93560  0.23%     -    0s
     0     0    0.93560    0   28    0.93780    0.93560  0.23%     -    0s
     0     2    0.93560    0   28    0.93780    0.93560  0.23%     -    0s

Cutting planes:
  Clique: 71
  MIR: 6
  Zero half: 14
  RLT: 5
  BQP: 7

Explored 56 nodes (7767 simplex iterations) in 0.77 seconds (1.40 work units)
Thread count was 32 (of 32 available processors)

Solution count 9: 0.9378 0.938 0.9386 ... 1

Optimal solution found (tolerance 1.00e-04)
Best objective 9.378000000000e-01, best bound 9.378000000000e-01, gap 0.0000%
FULL MODEL:
  Accruacy: 0.5016
  Our objective: 0.003200000000000036

IF 
    (x1 = 1 AND x3 = 1 AND x2 = 0)            <-- (term's our objective: 0.006400000000000017)
 OR (x0 = 0 AND x3 = 0 AND x4 = 0)            <-- (term's our objective: 0.038800000000000015)
 OR (x2 = 1 AND x3 = 1 AND x4 = 1 AND x1 = 0) <-- (term's our objective: 0.005599999999999966)
 OR (x1 = 1 AND x3 = 1 AND x4 = 0)            <-- (term's our objective: 0.01079999999999999)
 OR (x0 = 1 AND x2 = 1 AND x1 = 0 AND x4 = 0) <-- (term's our objective: 0.003200000000000036)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 10.273215770721436
Best over terms:
  Our final objective: 0.038800000000000015
    Its accruacy: 0.5194
    Its hamming distance: 2
  Shortest hamming distance: 2
    Its our objective: 0.038800000000000015
  Highest accruacy: 0.5194

Errors:

