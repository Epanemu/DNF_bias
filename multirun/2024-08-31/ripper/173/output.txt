Command:
python test_script.py -s smallest_subclass -d 5 -n 100 --seed 34 -m ripper --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.037500000000000006
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.06
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 100 remain. 
Dimension is 5.

Computed total variation: 0.45999999999999996
Importing dev version v0.982 of RIPPER
RIPPER:
FULL MODEL:
  Accruacy: 0.53
  Our objective: 0.06000000000000005

IF 
    (x4 = 0 AND x1 = 1) <-- (term's our objective: 0.12000000000000002)
 OR (x0 = 0)            <-- (term's our objective: 0.03999999999999998)
 OR (x1 = 1)            <-- (term's our objective: 0.06000000000000005)
 OR (x4 = 0 AND x2 = 1) <-- (term's our objective: 0.040000000000000036)
 OR (x2 = 0 AND x3 = 0) <-- (term's our objective: 0.04000000000000001)
 OR (x2 = 0 AND x4 = 1) <-- (term's our objective: -0.24)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 3.2671289443969727
Best over terms:
  Our final objective: 0.12000000000000002
    Its accruacy: 0.56
    Its hamming distance: 5
  Shortest hamming distance: 3
    Its our objective: 0.04000000000000001
  Highest accruacy: 0.56

Errors:

