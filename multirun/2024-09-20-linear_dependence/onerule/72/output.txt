Command:
python test_script.py -s linear_dependence -d 2 -n 10000 --seed 73 -m onerule -k 2 --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.6000000000000001
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.581
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 10000 remain. 
Dimension is 2.

Computed total variation: 0.581
One Rule (using MIO)
Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))

CPU model: Intel(R) Core(TM) i9-14900HX, instruction set [SSE2|AVX|AVX2]
Thread count: 24 physical cores, 32 logical processors, using up to 32 threads

Optimize a model with 25000 rows, 10004 columns and 45000 nonzeros
Model fingerprint: 0x2794c901
Variable types: 10000 continuous, 4 integer (4 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [2e-04, 2e-04]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
Found heuristic solution: objective 1.0000000
Presolve removed 24988 rows and 9992 columns
Presolve time: 0.02s
Presolved: 12 rows, 12 columns, 28 nonzeros
Variable types: 0 continuous, 12 integer (12 binary)

Root relaxation: objective 4.190000e-01, 9 iterations, 0.00 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

*    0     0               0       0.4190000    0.41900  0.00%     -    0s

Explored 1 nodes (9 simplex iterations) in 0.02 seconds (0.03 work units)
Thread count was 32 (of 32 available processors)

Solution count 2: 0.419 1 

Optimal solution found (tolerance 1.00e-04)
Best objective 4.190000000000e-01, best bound 4.190000000000e-01, gap 0.0000%
FULL MODEL:
  Accruacy: 0.7905
  Our objective: 0.581

IF 
    (x0 = 0) <-- (term's our objective: 0.581)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 1.179293155670166
Best over terms:
  Our final objective: 0.581
    Its accruacy: 0.7905
    Its hamming distance: 0
  Shortest hamming distance: 0
    Its our objective: 0.581
  Highest accruacy: 0.7905

Errors:

