Command:
python test_script.py -s linear_dependence -d 8 -n 500 --seed 43 -m onerule -k 8 --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.15000000000000002
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.164
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 500 remain. 
Dimension is 8.

Computed total variation: 0.5640000000000001
One Rule (using MIO)
Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))

CPU model: Intel(R) Core(TM) i9-14900HX, instruction set [SSE2|AVX|AVX2]
Thread count: 24 physical cores, 32 logical processors, using up to 32 threads

Optimize a model with 4250 rows, 516 columns and 8250 nonzeros
Model fingerprint: 0x575b0ff3
Variable types: 500 continuous, 16 integer (16 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [4e-03, 4e-03]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
Found heuristic solution: objective 1.0000000
Presolve removed 2848 rows and 190 columns
Presolve time: 0.00s
Presolved: 1402 rows, 326 columns, 3882 nonzeros
Variable types: 0 continuous, 326 integer (326 binary)
Found heuristic solution: objective 0.9360000

Root relaxation: objective 1.250000e-01, 360 iterations, 0.00 seconds (0.02 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.12500    0  172    0.93600    0.12500  86.6%     -    0s
H    0     0                       0.9320000    0.12500  86.6%     -    0s
H    0     0                       0.9280000    0.12500  86.5%     -    0s
H    0     0                       0.9240000    0.33600  63.6%     -    0s
     0     0    0.51650    0  151    0.92400    0.51650  44.1%     -    0s
     0     0    0.52050    0  155    0.92400    0.52050  43.7%     -    0s
     0     0    0.54560    0  153    0.92400    0.54560  41.0%     -    0s
H    0     0                       0.9200000    0.54560  40.7%     -    0s
     0     0    0.54560    0  153    0.92000    0.54560  40.7%     -    0s
     0     0    0.59143    0  159    0.92000    0.59143  35.7%     -    0s
H    0     0                       0.9040000    0.59143  34.6%     -    0s
     0     0    0.59400    0  159    0.90400    0.59400  34.3%     -    0s
     0     0    0.59400    0  158    0.90400    0.59400  34.3%     -    0s
H    0     0                       0.8840000    0.60291  31.8%     -    0s
     0     0    0.61067    0  161    0.88400    0.61067  30.9%     -    0s
     0     0    0.61067    0  130    0.88400    0.61067  30.9%     -    0s
     0     2    0.61067    0  130    0.88400    0.61067  30.9%     -    0s
*  184    23              13       0.8560000    0.70700  17.4%  36.6    0s
*  192    23              13       0.8360000    0.70700  15.4%  36.3    0s

Cutting planes:
  Gomory: 41
  Cover: 2
  Clique: 91
  MIR: 20
  Zero half: 24
  RLT: 42

Explored 230 nodes (8853 simplex iterations) in 0.28 seconds (0.43 work units)
Thread count was 32 (of 32 available processors)

Solution count 10: 0.836 0.856 0.884 ... 1

Optimal solution found (tolerance 1.00e-04)
Best objective 8.360000000000e-01, best bound 8.360000000000e-01, gap 0.0000%
FULL MODEL:
  Accruacy: 0.582
  Our objective: 0.16399999999999995

IF 
    (x0 = 0 AND x1 = 0 AND x2 = 0) <-- (term's our objective: 0.164)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 0.7081148624420166
Best over terms:
  Our final objective: 0.16399999999999995
    Its accruacy: 0.582
    Its hamming distance: 0
  Shortest hamming distance: 0
    Its our objective: 0.16399999999999995
  Highest accruacy: 0.582

Errors:

