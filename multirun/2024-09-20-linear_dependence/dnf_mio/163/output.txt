Command:
python test_script.py -s linear_dependence -d 5 -n 10 --seed 34 -m dnf_mio -k 5 --verbose
Output:
The true theoretical sup(\mu - \nu) = 0.30000000000000004
The correct rule on sampled data has \hat{\mu} - \hat{\nu} = 0.6
TRIVIAL ACCURACY - always TRUE: 0.5
Balancing dropped 0 samples, 10 remain. 
Dimension is 5.

Computed total variation: 1.0
DNF using MIO
Set parameter TimeLimit to value 120
Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))

CPU model: Intel(R) Core(TM) i9-14900HX, instruction set [SSE2|AVX|AVX2]
Thread count: 24 physical cores, 32 logical processors, using up to 32 threads

Optimize a model with 280 rows, 85 columns and 555 nonzeros
Model fingerprint: 0xd15f2e64
Variable types: 35 continuous, 50 integer (50 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [2e-01, 2e-01]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 4e+00]
Found heuristic solution: objective 0.4000000
Presolve removed 273 rows and 72 columns
Presolve time: 0.00s
Presolved: 7 rows, 13 columns, 27 nonzeros
Variable types: 0 continuous, 13 integer (13 binary)
Found heuristic solution: objective 0.0000000

Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)
Thread count was 32 (of 32 available processors)

Solution count 2: 0 0.4 

Optimal solution found (tolerance 1.00e-04)
Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%
FULL MODEL:
  Accruacy: 0.8
  Our objective: 0.6

IF 
    (x0 = 0 AND x1 = 0) <-- (term's our objective: 0.6)
 OR (x1 = 0 AND x4 = 1) <-- (term's our objective: 0.6)
 OR (x1 = 0 AND x4 = 1) <-- (term's our objective: 0.6)
 OR (x1 = 0 AND x4 = 1) <-- (term's our objective: 0.6)
 OR (x1 = 0 AND x4 = 1) <-- (term's our objective: 0.6)
THEN
 target = 1.0 ELSE target = 0.0

Seconds needed: 0.3245077133178711
Best over terms:
  Our final objective: 0.6
    Its accruacy: 0.8
    Its hamming distance: 2
  Shortest hamming distance: 0
    Its our objective: 0.6
  Highest accruacy: 0.8

Errors:

